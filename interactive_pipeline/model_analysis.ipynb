{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prerequisites"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TensorFlow Extended와 TensorFlow가 깔려 있다면 이 셀은 스킵.\n",
    "!pip install tfx\n",
    "!pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 05:15:59.999602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tfx\n",
    "from tfx.components import (ImportExampleGen,\n",
    "                            StatisticsGen, SchemaGen, ExampleValidator,\n",
    "                            Transform, Trainer, Evaluator, Pusher)\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.v1.dsl import Resolver\n",
    "from tfx.v1.dsl.experimental import LatestBlessedModelStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def copy_artifact(component, root_dir):\n",
    "    for key, output in component.outputs.items():\n",
    "        src = output.get()[0].uri\n",
    "        dest = pathlib.Path(os.path.join(root_dir, key))\n",
    "        shutil.copytree(src, dest, dirs_exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "record_dir = pathlib.Path(\"data/complaints/records\")\n",
    "artifact_dir = pathlib.Path(\"artifacts\")\n",
    "transform_module = \"transform_module.py\"\n",
    "trainer_module = \"trainer_module.py\"\n",
    "_serving_model_dir = \"serving_model_dir\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:InteractiveContext pipeline_root argument not provided: using temporary directory /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr as root for pipeline outputs.\n",
      "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/metadata.sqlite.\n"
     ]
    }
   ],
   "source": [
    "context = InteractiveContext()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. ExampleGen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "example_gen = ImportExampleGen(input_base=str(record_dir))\n",
    "context.run(example_gen)\n",
    "examples = example_gen.outputs[\"examples\"]\n",
    "copy_artifact(example_gen, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. StatisticsGen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "statistics_gen = StatisticsGen(examples=examples)\n",
    "context.run(statistics_gen)\n",
    "stats = statistics_gen.outputs[\"statistics\"]\n",
    "copy_artifact(statistics_gen, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. SchemaGen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "schema_gen = SchemaGen(statistics=stats, infer_feature_shape=True)\n",
    "context.run(schema_gen)\n",
    "schema = schema_gen.outputs[\"schema\"]\n",
    "copy_artifact(schema_gen, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. ExampleValidator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "example_validator = ExampleValidator(statistics=stats, schema=schema)\n",
    "context.run(example_validator)\n",
    "anomalies = example_validator.outputs[\"anomalies\"]\n",
    "copy_artifact(example_validator, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Transform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying transform_module.py -> build/lib\n",
      "copying trainer_module.py -> build/lib\n",
      "installing to /tmp/tmpz0dauhlz\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/transform_module.py -> /tmp/tmpz0dauhlz\n",
      "copying build/lib/trainer_module.py -> /tmp/tmpz0dauhlz\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmpz0dauhlz/tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpz0dauhlz/tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/WHEEL\n",
      "creating '/tmp/tmpuidnbec5/tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64-py3-none-any.whl' and adding '/tmp/tmpz0dauhlz' to it\n",
      "adding 'trainer_module.py'\n",
      "adding 'transform_module.py'\n",
      "adding 'tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/RECORD'\n",
      "removing /tmp/tmpz0dauhlz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/_wheels/tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64\n",
      "Processing /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/_wheels/tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64\n",
      "Processing /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/_wheels/tfx_user_code_Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 05:19:03.861400: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:324: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:324: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/Transform/transform_graph/7/.temp_path/tftransform_tmp/7e6de2cd6bed434493d531149f0bf622/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/Transform/transform_graph/7/.temp_path/tftransform_tmp/7e6de2cd6bed434493d531149f0bf622/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/Transform/transform_graph/7/.temp_path/tftransform_tmp/94dd1c4db40d43db99c23fa0bb784f76/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/Transform/transform_graph/7/.temp_path/tftransform_tmp/94dd1c4db40d43db99c23fa0bb784f76/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    }
   ],
   "source": [
    "transform = Transform(examples=examples,\n",
    "                      schema=schema,\n",
    "                      module_file=transform_module)\n",
    "context.run(transform)\n",
    "transform_graph = transform.outputs[\"transform_graph\"]\n",
    "transformed_examples = transform.outputs[\"transformed_examples\"]\n",
    "copy_artifact(transform, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying transform_module.py -> build/lib\n",
      "copying trainer_module.py -> build/lib\n",
      "installing to /tmp/tmpy7izb9_f\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/transform_module.py -> /tmp/tmpy7izb9_f\n",
      "copying build/lib/trainer_module.py -> /tmp/tmpy7izb9_f\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmpy7izb9_f/tfx_user_code_Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpy7izb9_f/tfx_user_code_Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/WHEEL\n",
      "creating '/tmp/tmpq_o8qioj/tfx_user_code_Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64-py3-none-any.whl' and adding '/tmp/tmpy7izb9_f' to it\n",
      "adding 'trainer_module.py'\n",
      "adding 'transform_module.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64.dist-info/RECORD'\n",
      "removing /tmp/tmpy7izb9_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /tmp/tfx-interactive-2023-01-14T05_16_20.442478-w492wnpr/_wheels/tfx_user_code_Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+8d583d042595efa91bdc0a51985ccb9118c9b9a0a3ae81b0eb56cfc5d1c3be64\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 0s - loss: 0.5889 - binary_accuracy: 0.7225 - true_positives: 17.0000"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(examples=transformed_examples,\n",
    "                  transform_graph=transform_graph,\n",
    "                  schema=schema, module_file=trainer_module,\n",
    "                  train_args=tfx.proto.trainer_pb2.TrainArgs(num_steps=50),\n",
    "                  eval_args=tfx.proto.trainer_pb2.EvalArgs(num_steps=10))\n",
    "context.run(trainer)\n",
    "trained_model = trainer.outputs[\"model\"]\n",
    "copy_artifact(trainer, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Resolver"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_resolver = Resolver(\n",
    "    strategy_class=LatestBlessedModelStrategy,\n",
    "    model=Channel(type=Model),\n",
    "    model_blessing=Channel(type=ModelBlessing)\n",
    ").with_id(\"latest_blessed_model_resolver\")\n",
    "context.run(model_resolver)\n",
    "copy_artifact(model_resolver, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Evaluator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[tfma.ModelSpec(label_key=\"consumer_disputed\")],\n",
    "    slicing_specs=[tfma.SlicingSpec(), tfma.SlicingSpec(feature_keys=[\"product\"])],\n",
    "    metrics_specs=[\n",
    "        tfma.MetricsSpec(\n",
    "            metrics=[\n",
    "                tfma.MetricConfig(class_name=\"BinaryAccuracy\"),\n",
    "                tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "                tfma.MetricConfig(class_name=\"AUC\")],\n",
    "            # baseline 모델과 비교해 우위에 있더라도 아래 임계치를 넘어야 bless를 받는다.\n",
    "            thresholds={\n",
    "                \"AUC\": tfma.MetricThreshold(\n",
    "                    value_threshold=tfma.GenericValueThreshold(\n",
    "                        lower_bound={\"value\": 0.65}),\n",
    "                    # 두 모델 간 지표 ∆가 0.01은 넘어야 하고, 새 모델 지표값은 클수록 좋다는 의미.\n",
    "                    change_threshold=tfma.GenericChangeThreshold(\n",
    "                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                        absolute={\"value\": 0.01}))})])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluator = Evaluator(\n",
    "    examples=examples,\n",
    "    model=trained_model,\n",
    "    baseline_model=model_resolver.outputs[\"model\"],\n",
    "    eval_config=eval_config)\n",
    "context.run(evaluator)\n",
    "blessing = evaluator.outputs[\"blessing\"]\n",
    "evaluation = evaluator.outputs[\"evaluation\"]\n",
    "copy_artifact(evaluator, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_path = evaluator.outputs['evaluation'].get()[0].uri\n",
    "tfma_result = tfma.load_eval_result(output_path)\n",
    "validation_result = tfma.load_validation_result(output_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Pusher"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pusher = Pusher(model=trained_model,\n",
    "                model_blessing=blessing,\n",
    "                push_destination=pusher_pb2.PushDestination(\n",
    "                    filesystem=pusher_pb2.PushDestination.Filesystem(base_directory=_serving_model_dir)))\n",
    "context.run(pusher)\n",
    "pushed_model = pusher.outputs[\"pushed_model\"]\n",
    "copy_artifact(pusher, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
