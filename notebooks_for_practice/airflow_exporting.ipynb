{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 18:04:06.793192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tfx.components import (ImportExampleGen, StatisticsGen, SchemaGen,\n",
    "                            ExampleValidator, Transform, Trainer, Evaluator,\n",
    "                            Pusher)\n",
    "from tfx.dsl.components.common.resolver import Resolver\n",
    "from tfx.components.base import executor_spec\n",
    "from tfx.components.trainer.executor import GenericExecutor\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
    "from tfx.proto import pusher_pb2, trainer_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.v1.dsl.experimental import LatestBlessedModelStrategy\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.orchestration import metadata, pipeline\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def init_components(data_dir,\n",
    "                    modules: dict,\n",
    "                    serving_model_dir,\n",
    "                    training_steps=100,\n",
    "                    eval_steps=50):\n",
    "    # Config.\n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[tfma.ModelSpec(label_key=\"consumer_disputed\")],\n",
    "        slicing_specs=[tfma.SlicingSpec(), tfma.SlicingSpec(feature_keys=[\"product\"])],\n",
    "        metrics_specs=[\n",
    "            tfma.MetricsSpec(\n",
    "                metrics=[\n",
    "                    tfma.MetricConfig(class_name=\"BinaryAccuracy\"),\n",
    "                    tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "                    tfma.MetricConfig(class_name=\"AUC\")],\n",
    "                thresholds={\n",
    "                    \"AUC\": tfma.MetricThreshold(\n",
    "                        value_threshold=tfma.GenericValueThreshold(\n",
    "                            lower_bound={\"value\": 0.65}),\n",
    "                        change_threshold=tfma.GenericChangeThreshold(\n",
    "                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                            absolute={\"value\": 0.01}))})])\n",
    "\n",
    "    # Components\n",
    "    # 1. Example generation\n",
    "    example_gen = ImportExampleGen(input_base=data_dir)\n",
    "    examples = example_gen.outputs[\"examples\"]\n",
    "    print(\"1. Example gathering finished.\")\n",
    "\n",
    "    # Get example statistics\n",
    "    statistics_gen = StatisticsGen(examples=examples)\n",
    "    stats = statistics_gen.outputs[\"statistics\"]\n",
    "    print(\"2. Statistics calculation finished.\")\n",
    "\n",
    "    # Get example schema\n",
    "    schema_gen = SchemaGen(statistics=stats)\n",
    "    schema = schema_gen.outputs[\"schema\"]\n",
    "    print(\"3. Schema generation finished.\")\n",
    "\n",
    "    # Example validation\n",
    "    example_validator = ExampleValidator(statistics=stats, schema=schema)\n",
    "    anomalies = example_validator.outputs[\"anomalies\"]\n",
    "    print(\"4. Example validation finished.\")\n",
    "\n",
    "    # Data transform\n",
    "    transform = Transform(examples=examples,\n",
    "                          schema=schema,\n",
    "                          module_file=modules['transform'])\n",
    "    transformed_examples = transform.outputs[\"transformed_examples\"]\n",
    "    transform_graph = transform.outputs[\"transform_graph\"]\n",
    "    print(\"5. Data transformation finished.\")\n",
    "\n",
    "    # Model training\n",
    "    trainer = Trainer(examples=examples,\n",
    "                      transform_graph=transform_graph,\n",
    "                      schema=schema,\n",
    "                      module_file=modules[\"trainer\"],\n",
    "                      train_args=trainer_pb2.TrainArgs(num_steps=training_steps),\n",
    "                      eval_args=trainer_pb2.EvalArgs(num_steps=eval_steps))\n",
    "    model = trainer.outputs[\"model\"]\n",
    "    print(\"6. Model training finished.\")\n",
    "\n",
    "    # Model resolving(choose one among conflicting models.)\n",
    "    resolver = Resolver(\n",
    "        strategy_class=LatestBlessedModelStrategy,\n",
    "        model=Channel(type=Model),\n",
    "        model_blessing=Channel(type=ModelBlessing)\n",
    "    ).with_id(\"latest_blessed_model_resolver\")\n",
    "    print(\"7. Model resolving finished.\")\n",
    "\n",
    "    # Model evaluation\n",
    "    evaluator = Evaluator(\n",
    "        examples=examples,\n",
    "        model=model,\n",
    "        baseline_model=resolver.outputs[\"model\"],\n",
    "        eval_config=eval_config)\n",
    "    blessing = evaluator.outputs[\"blessing\"]\n",
    "    evaluation = evaluator.outputs[\"evaluation\"]\n",
    "    print(\"8. Model evaluation finished.\")\n",
    "\n",
    "    # Model pushing\n",
    "    push_filesystem = pusher_pb2.PushDestination.Filesystem(base_directory=serving_model_dir)\n",
    "    push_destination = pusher_pb2.PushDestination(filesystem=push_filesystem)\n",
    "    pusher = Pusher(model=model,\n",
    "                    model_blessing=blessing,\n",
    "                    push_destination=push_destination)\n",
    "    print(\"9. Model pushing finished.\")\n",
    "\n",
    "    components = [example_gen, statistics_gen, schema_gen, example_validator,\n",
    "                  transform, trainer, resolver, evaluator, pusher]\n",
    "    return components\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:InteractiveContext pipeline_root argument not provided: using temporary directory /tmp/tfx-interactive-2023-01-15T18_04_14.315735-qobpqfy2 as root for pipeline outputs.\n",
      "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /tmp/tfx-interactive-2023-01-15T18_04_14.315735-qobpqfy2/metadata.sqlite.\n"
     ]
    }
   ],
   "source": [
    "context = InteractiveContext()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 파이프라인 정의를 위한 인자들\n",
    "\n",
    "# `_`로 시작하는 경로들은 내보내기 시 생성되는 스크립트에서 요구하는 경로명이다.\n",
    "# 바꾸지 말고 그대로 사용해야 하며, 빼놓지 말고 정의해야 할 것들이기도 하다.\n",
    "_pipeline_root = \"pipeline_root\"\n",
    "_pipeline_name = \"consumer_complaints\"\n",
    "_metadata_path = os.path.join(_pipeline_root, \"metadata.sqlite\")  # Default for MLMD is SQLite."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 컴포넌트 인스턴스들 생성을 위한 인자들\n",
    "project_dir = \"/home/hakjun/projects/pipeline\"\n",
    "data_dir = os.path.join(project_dir, \"data/complaints/records\")\n",
    "serving_model_dir = os.path.join(_pipeline_root, \"serving_models\")\n",
    "modules = {\n",
    "    \"trainer\": os.path.join(project_dir, \"trainer_module.py\"),\n",
    "    \"transform\": os.path.join(project_dir, \"transform_module.py\")}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "notebook_filepath = os.path.join(os.getcwd(), \"airflow_exporting.ipynb\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Example gathering finished.\n",
      "2. Statistics calculation finished.\n",
      "3. Schema generation finished.\n",
      "4. Example validation finished.\n",
      "5. Data transformation finished.\n",
      "6. Model training finished.\n",
      "7. Model resolving finished.\n",
      "8. Model evaluation finished.\n",
      "9. Model pushing finished.\n"
     ]
    }
   ],
   "source": [
    "components = init_components(data_dir=data_dir,\n",
    "                             modules=modules,\n",
    "                             serving_model_dir=serving_model_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "_airflow_config = {\n",
    "    \"schedule_interval\": None,\n",
    "    \"start_date\": datetime.today()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "export_filepath = \"airflow_pipeline.py\"\n",
    "runner_type = \"airflow\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "context.export_to_pipeline(notebook_filepath=notebook_filepath,\n",
    "                           export_filepath=export_filepath,\n",
    "                           runner_type=runner_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
