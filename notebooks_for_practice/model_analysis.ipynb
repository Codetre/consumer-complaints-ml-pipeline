{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TensorFlow Extended와 TensorFlow가 깔려 있다면 이 셀은 스킵.\n",
    "!pip install tfx\n",
    "!pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 03:55:56.211802: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tfx\n",
    "from tfx.components import (ImportExampleGen,\n",
    "                            StatisticsGen, SchemaGen, ExampleValidator,\n",
    "                            Transform, Trainer, Evaluator, Pusher)\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.v1.dsl import Resolver\n",
    "from tfx.v1.dsl.experimental import LatestBlessedModelStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 09:36:41.018043: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"models/1\"\n",
    "model_ver = os.path.split(model_dir)[-1]\n",
    "trained_model = tf.saved_model.load(model_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[TFMA에 아직도 `EvalSharedModel`이 꼭 필요한가?](https://www.tensorflow.org/tfx/model_analysis/faq#is_an_evalsavedmodel_still_required)에 대한 답변."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# SavedModel을 TFMA로 평가하기 위해 필요한 객체 형식(`EvalSharedModel`)으로 불러들여야 한다.\n",
    "eval_shared_model = tfma.default_eval_shared_model(\n",
    "    eval_saved_model_path=model_dir,\n",
    "    tags=[tf.saved_model.SERVING]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "eval_data_file = os.path.join(\"data\", \"complaints\", \"splits\",\n",
    "                              \"small-from-eval.tfrecord\")  # VM instance에 CPU만 달려 있어 추론 시간 상 100 example들만.\n",
    "eval_result_location = os.path.join(\"metadata\", \"eval_results\", model_ver)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "eval_config = tfma.EvalConfig(\n",
    "    # 모델 정답 레이블 지정.\n",
    "    model_specs=[\n",
    "        # `tfma.ModelSpec.model_type=tfma.TF_LITE`로 설정하면 TFLite 모델도 분석 가능.\n",
    "        tfma.ModelSpec(label_key=\"consumer_disputed\",\n",
    "                       # signature_name=\"serving_default\",\n",
    "                       # preprocessing_function_names=\"serving_default\"\n",
    "                       )],\n",
    "    # 데이터 슬라이스: 여기선 전체 데이터셋의 모든 피처를 대상으로 평가한다. 특정 피처 대상으로 분석도 가능.\n",
    "    slicing_specs=[tfma.SlicingSpec()],\n",
    "    # `EvalSharedModel`을 대상으로 평가하려는 지표 나열.\n",
    "    metrics_specs=[tfma.MetricsSpec(metrics=[\n",
    "        tfma.MetricConfig(class_name=\"BinaryAccuracy\"),\n",
    "        tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "        tfma.MetricConfig(class_name=\"FalsePositives\"),\n",
    "        tfma.MetricConfig(class_name=\"TruePositives\"),\n",
    "        tfma.MetricConfig(class_name=\"FalseNegatives\"),\n",
    "        tfma.MetricConfig(class_name=\"TrueNegatives\"), ])])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Tensorflow version (2.11.0) found. Note that TFMA support for TF 2.0 is currently in beta\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: \n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "# 모델 분석 실행\n",
    "eval_result = tfma.run_model_analysis(\n",
    "    eval_shared_model=eval_shared_model,\n",
    "    eval_config=eval_config,\n",
    "    data_location=eval_data_file,\n",
    "    output_path=eval_result_location,\n",
    "    # `data_location`에서 지정한 평가 파일 형식 지정.\n",
    "    file_format=\"tfrecords\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "EvalResult(slicing_metrics=[((), {'': {'': {'example_count': {'doubleValue': 100.0}, 'binary_accuracy': {'doubleValue': 0.7}, 'false_positives': {'doubleValue': 0.0}, 'true_positives': {'doubleValue': 0.0}, 'false_negatives': {'doubleValue': 30.0}, 'true_negatives': {'doubleValue': 70.0}}}})], plots=[((), None)], attributions=[((), None)], config=model_specs {\n  label_key: \"consumer_disputed\"\n}\nslicing_specs {\n}\nmetrics_specs {\n  metrics {\n    class_name: \"BinaryAccuracy\"\n  }\n  metrics {\n    class_name: \"ExampleCount\"\n  }\n  metrics {\n    class_name: \"FalsePositives\"\n  }\n  metrics {\n    class_name: \"TruePositives\"\n  }\n  metrics {\n    class_name: \"FalseNegatives\"\n  }\n  metrics {\n    class_name: \"TrueNegatives\"\n  }\n  model_names: \"\"\n}\n, data_location='data/complaints/splits/small-from-eval.tfrecord', file_format='tfrecords', model_location='models/1')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "SlicingMetricsViewer(config={'weightedExamplesColumn': 'example_count'}, data=[{'slice': 'Overall', 'metrics':…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8db151e5dfb4105b448ad2ce8fd0f8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_slicing_metrics(eval_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 복수 모델 비교\n",
    "그래프 구조는 동일. 스텝만 조정.\n",
    "       | train_steps | eval_steps |\n",
    "model1 |    100      |     50     |\n",
    "model2 |    500      |     100    |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model_dir2 = \"models/2\"\n",
    "model_ver2 = os.path.split(model_dir2)[-1]\n",
    "eval_result_location2 = os.path.join(\"metadata\", \"eval_results\", model_ver2)\n",
    "\n",
    "eval_shared_model2 = tfma.default_eval_shared_model(\n",
    "    eval_saved_model_path=model_dir2,\n",
    "    tags=[tf.saved_model.SERVING])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Tensorflow version (2.11.0) found. Note that TFMA support for TF 2.0 is currently in beta\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "eval_result2 = tfma.run_model_analysis(\n",
    "    eval_shared_model=eval_shared_model2,\n",
    "    eval_config=eval_config,\n",
    "    data_location=eval_data_file,\n",
    "    output_path=eval_result_location2,\n",
    "    # `data_location`에서 지정한 평가 파일 형식 지정.\n",
    "    file_format=\"tfrecords\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "eval_result_locations = [eval_result_location, eval_result_location2]\n",
    "\n",
    "eval_results_from_disk = tfma.load_eval_results(\n",
    "    eval_result_locations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "TimeSeriesViewer(config={'isModelCentric': True}, data=[{'metrics': {'': {'': {'example_count': {'doubleValue'…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b067a83c89a4e5bb61b9524bbde7234"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_time_series(eval_results_from_disk)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TFX 컴포넌트를 이용한 분석\n",
    "\n",
    "blessing: 검사할 모델이 기준으로 삼은 모델(baseline이라고 부른다)보다 더 낫고, 설정한 평가 기준을\n",
    "넘는다면 그 모델에게 합격을 주는 일을 말한다.\n",
    "\n",
    "\n",
    "사용되는 컴포넌트:\n",
    "  - `Resolver`: 여러 모델 간 어떤 것을 선택할지 결정하는 역할을 `Evaluator` 의 일부로 담당.\n",
    "    - 단 이 컴포넌트는 다른 컴포넌트와 달리 `tfx.v1.dsl`에서 찾아야 한다. `v1`은 레거시로 남은\n",
    "        모양인데, 이게 지금은 어떻게 바뀌었는지 조사해볼 만한 주제다.\n",
    "  - `Evaluator`: 모델들의 지표를 분석 비교해 blessing 여부를 결정한다.\n",
    "  - `Pusher`: blessed 상태 모델을 내보내는 역할을 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def copy_artifact(component, root_dir):\n",
    "    for key, output in component.outputs.items():\n",
    "        src = output.get()[0].uri\n",
    "        dest = pathlib.Path(os.path.join(root_dir, key))\n",
    "        shutil.copytree(src, dest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:InteractiveContext pipeline_root argument not provided: using temporary directory /tmp/tfx-interactive-2023-01-14T03_56_20.076675-lwnn3dm7 as root for pipeline outputs.\n",
      "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /tmp/tfx-interactive-2023-01-14T03_56_20.076675-lwnn3dm7/metadata.sqlite.\n"
     ]
    }
   ],
   "source": [
    "context = InteractiveContext()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    }
   ],
   "source": [
    "record_dir = \"data/complaints/records\"\n",
    "example_gen = ImportExampleGen(input_base=record_dir)\n",
    "context.run(example_gen)\n",
    "examples = example_gen.outputs[\"examples\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "artifact_dir = pathlib.Path(\"artifacts\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "copy_artifact(example_gen, artifact_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "statistics_gen = StatisticsGen(examples=examples)\n",
    "context.run(statistics_gen)\n",
    "stats = statistics_gen.outputs[\"statistics\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "schema_gen = SchemaGen(statistics=stats, infer_feature_shape=True)\n",
    "context.run(schema_gen)\n",
    "schema = schema_gen.outputs[\"schema\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "example_validator = ExampleValidator(statistics=stats, schema=schema)\n",
    "context.run(example_validator)\n",
    "anomalies = example_validator.outputs[\"anomalies\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying transform_module.py -> build/lib\n",
      "copying trainer_module.py -> build/lib\n",
      "copying hello.py -> build/lib\n",
      "installing to /tmp/tmpwnyukrst\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/transform_module.py -> /tmp/tmpwnyukrst\n",
      "copying build/lib/trainer_module.py -> /tmp/tmpwnyukrst\n",
      "copying build/lib/hello.py -> /tmp/tmpwnyukrst\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmpwnyukrst/tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpwnyukrst/tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/WHEEL\n",
      "creating '/tmp/tmpa1bhkfxa/tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f-py3-none-any.whl' and adding '/tmp/tmpwnyukrst' to it\n",
      "adding 'hello.py'\n",
      "adding 'trainer_module.py'\n",
      "adding 'transform_module.py'\n",
      "adding 'tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/RECORD'\n",
      "removing /tmp/tmpwnyukrst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/_wheels/tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f\n",
      "Processing /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/_wheels/tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f\n",
      "Processing /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/_wheels/tfx_user_code_Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 16:17:54.192466: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:324: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:324: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/Transform/transform_graph/5/.temp_path/tftransform_tmp/c1af09b0ae4147c58bd8616c6203559e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/Transform/transform_graph/5/.temp_path/tftransform_tmp/c1af09b0ae4147c58bd8616c6203559e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/Transform/transform_graph/5/.temp_path/tftransform_tmp/7c969daf519f42aba0266952fbed05ec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/Transform/transform_graph/5/.temp_path/tftransform_tmp/7c969daf519f42aba0266952fbed05ec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    }
   ],
   "source": [
    "transform = Transform(examples=examples, schema=schema, module_file=\"transform_module.py\")\n",
    "context.run(transform)\n",
    "transform_graph = transform.outputs[\"transform_graph\"]\n",
    "transformed_examples = transform.outputs[\"transformed_examples\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying transform_module.py -> build/lib\n",
      "copying trainer_module.py -> build/lib\n",
      "copying hello.py -> build/lib\n",
      "installing to /tmp/tmpofzlq_n1\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/transform_module.py -> /tmp/tmpofzlq_n1\n",
      "copying build/lib/trainer_module.py -> /tmp/tmpofzlq_n1\n",
      "copying build/lib/hello.py -> /tmp/tmpofzlq_n1\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmpofzlq_n1/tfx_user_code_Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpofzlq_n1/tfx_user_code_Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/WHEEL\n",
      "creating '/tmp/tmp7xfnz82v/tfx_user_code_Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f-py3-none-any.whl' and adding '/tmp/tmpofzlq_n1' to it\n",
      "adding 'hello.py'\n",
      "adding 'trainer_module.py'\n",
      "adding 'transform_module.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f.dist-info/RECORD'\n",
      "removing /tmp/tmpofzlq_n1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/_wheels/tfx_user_code_Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+3100132ed8ea60cb8773f45a92a4da856ccdce929d65b49a4bf28e3401c1242f\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hakjun/projects/pipeline/venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 7s 66ms/step - loss: 0.4658 - binary_accuracy: 0.8081 - true_positives: 331.0000 - val_loss: 0.8020 - val_binary_accuracy: 0.5156 - val_true_positives: 9.0000\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/Trainer/model/6/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tfx-interactive-2023-01-13T16_17_31.357854-nhcsbetp/Trainer/model/6/Format-Serving/assets\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(examples=transformed_examples,\n",
    "                  transform_graph=transform_graph,\n",
    "                  schema=schema, module_file=\"trainer_module.py\",\n",
    "                  train_args=tfx.proto.trainer_pb2.TrainArgs(num_steps=50),\n",
    "                  eval_args=tfx.proto.trainer_pb2.EvalArgs(num_steps=10))\n",
    "context.run(trainer)\n",
    "trained_model = trainer.outputs[\"model\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "ExecutionResult(\n    component_id: latest_blessed_model_resolver\n    execution_id: 7\n    outputs:\n        model: OutputChannel(artifact_type=Model, producer_component_id=latest_blessed_model_resolver, output_key=model, additional_properties={}, additional_custom_properties={})\n        model_blessing: OutputChannel(artifact_type=ModelBlessing, producer_component_id=latest_blessed_model_resolver, output_key=model_blessing, additional_properties={}, additional_custom_properties={}))",
      "text/html": "<style>\n.tfx-object.expanded {\n  padding: 4px 8px 4px 8px;\n  background: white;\n  border: 1px solid #bbbbbb;\n  box-shadow: 4px 4px 2px rgba(0,0,0,0.05);\n}\nhtml[theme=dark] .tfx-object.expanded {\n  background: black;\n}\n.tfx-object, .tfx-object * {\n  font-size: 11pt;\n}\n.tfx-object > .title {\n  cursor: pointer;\n}\n.tfx-object .expansion-marker {\n  color: #999999;\n}\n.tfx-object.expanded > .title > .expansion-marker:before {\n  content: '▼';\n}\n.tfx-object.collapsed > .title > .expansion-marker:before {\n  content: '▶';\n}\n.tfx-object .class-name {\n  font-weight: bold;\n}\n.tfx-object .deemphasize {\n  opacity: 0.5;\n}\n.tfx-object.collapsed > table.attr-table {\n  display: none;\n}\n.tfx-object.expanded > table.attr-table {\n  display: block;\n}\n.tfx-object table.attr-table {\n  border: 2px solid white;\n  margin-top: 5px;\n}\nhtml[theme=dark] .tfx-object table.attr-table {\n  border: 2px solid black;\n}\n.tfx-object table.attr-table td.attr-name {\n  vertical-align: top;\n  font-weight: bold;\n}\n.tfx-object table.attr-table td.attrvalue {\n  text-align: left;\n}\n</style>\n<script>\nfunction toggleTfxObject(element) {\n  var objElement = element.parentElement;\n  if (objElement.classList.contains('collapsed')) {\n    objElement.classList.remove('collapsed');\n    objElement.classList.add('expanded');\n  } else {\n    objElement.classList.add('collapsed');\n    objElement.classList.remove('expanded');\n  }\n}\n</script>\n<div class=\"tfx-object expanded\"><div class = \"title\" onclick=\"toggleTfxObject(this)\"><span class=\"expansion-marker\"></span><span class=\"class-name\">ExecutionResult</span><span class=\"deemphasize\"> at 0x7f7e577a6fa0</span></div><table class=\"attr-table\"><tr><td class=\"attr-name\">.execution_id</td><td class = \"attrvalue\">7</td></tr><tr><td class=\"attr-name\">.component</td><td class = \"attrvalue\">&lt;tfx.dsl.components.common.resolver.Resolver object at 0x7f7e575956a0&gt;</td></tr><tr><td class=\"attr-name\">.component.inputs</td><td class = \"attrvalue\"><table class=\"attr-table\"><tr><td class=\"attr-name\">['model']</td><td class = \"attrvalue\">&lt;tfx.types.resolved_channel.ResolvedChannel object at 0x7f7e5759bdf0&gt;</td></tr><tr><td class=\"attr-name\">['model_blessing']</td><td class = \"attrvalue\">&lt;tfx.types.resolved_channel.ResolvedChannel object at 0x7f7e57649b80&gt;</td></tr></table></td></tr><tr><td class=\"attr-name\">.component.outputs</td><td class = \"attrvalue\"><table class=\"attr-table\"><tr><td class=\"attr-name\">['model']</td><td class = \"attrvalue\"><style>\n.tfx-object.expanded {\n  padding: 4px 8px 4px 8px;\n  background: white;\n  border: 1px solid #bbbbbb;\n  box-shadow: 4px 4px 2px rgba(0,0,0,0.05);\n}\nhtml[theme=dark] .tfx-object.expanded {\n  background: black;\n}\n.tfx-object, .tfx-object * {\n  font-size: 11pt;\n}\n.tfx-object > .title {\n  cursor: pointer;\n}\n.tfx-object .expansion-marker {\n  color: #999999;\n}\n.tfx-object.expanded > .title > .expansion-marker:before {\n  content: '▼';\n}\n.tfx-object.collapsed > .title > .expansion-marker:before {\n  content: '▶';\n}\n.tfx-object .class-name {\n  font-weight: bold;\n}\n.tfx-object .deemphasize {\n  opacity: 0.5;\n}\n.tfx-object.collapsed > table.attr-table {\n  display: none;\n}\n.tfx-object.expanded > table.attr-table {\n  display: block;\n}\n.tfx-object table.attr-table {\n  border: 2px solid white;\n  margin-top: 5px;\n}\nhtml[theme=dark] .tfx-object table.attr-table {\n  border: 2px solid black;\n}\n.tfx-object table.attr-table td.attr-name {\n  vertical-align: top;\n  font-weight: bold;\n}\n.tfx-object table.attr-table td.attrvalue {\n  text-align: left;\n}\n</style>\n<script>\nfunction toggleTfxObject(element) {\n  var objElement = element.parentElement;\n  if (objElement.classList.contains('collapsed')) {\n    objElement.classList.remove('collapsed');\n    objElement.classList.add('expanded');\n  } else {\n    objElement.classList.add('collapsed');\n    objElement.classList.remove('expanded');\n  }\n}\n</script>\n<div class=\"tfx-object collapsed\"><div class = \"title\" onclick=\"toggleTfxObject(this)\"><span class=\"expansion-marker\"></span><span class=\"class-name\">Channel</span> of type <span class=\"class-name\">'Model'</span> (0 artifacts)<span class=\"deemphasize\"> at 0x7f7e573502e0</span></div><table class=\"attr-table\"><tr><td class=\"attr-name\">.type_name</td><td class = \"attrvalue\">Model</td></tr><tr><td class=\"attr-name\">._artifacts</td><td class = \"attrvalue\">[]</td></tr></table></div></td></tr><tr><td class=\"attr-name\">['model_blessing']</td><td class = \"attrvalue\"><style>\n.tfx-object.expanded {\n  padding: 4px 8px 4px 8px;\n  background: white;\n  border: 1px solid #bbbbbb;\n  box-shadow: 4px 4px 2px rgba(0,0,0,0.05);\n}\nhtml[theme=dark] .tfx-object.expanded {\n  background: black;\n}\n.tfx-object, .tfx-object * {\n  font-size: 11pt;\n}\n.tfx-object > .title {\n  cursor: pointer;\n}\n.tfx-object .expansion-marker {\n  color: #999999;\n}\n.tfx-object.expanded > .title > .expansion-marker:before {\n  content: '▼';\n}\n.tfx-object.collapsed > .title > .expansion-marker:before {\n  content: '▶';\n}\n.tfx-object .class-name {\n  font-weight: bold;\n}\n.tfx-object .deemphasize {\n  opacity: 0.5;\n}\n.tfx-object.collapsed > table.attr-table {\n  display: none;\n}\n.tfx-object.expanded > table.attr-table {\n  display: block;\n}\n.tfx-object table.attr-table {\n  border: 2px solid white;\n  margin-top: 5px;\n}\nhtml[theme=dark] .tfx-object table.attr-table {\n  border: 2px solid black;\n}\n.tfx-object table.attr-table td.attr-name {\n  vertical-align: top;\n  font-weight: bold;\n}\n.tfx-object table.attr-table td.attrvalue {\n  text-align: left;\n}\n</style>\n<script>\nfunction toggleTfxObject(element) {\n  var objElement = element.parentElement;\n  if (objElement.classList.contains('collapsed')) {\n    objElement.classList.remove('collapsed');\n    objElement.classList.add('expanded');\n  } else {\n    objElement.classList.add('collapsed');\n    objElement.classList.remove('expanded');\n  }\n}\n</script>\n<div class=\"tfx-object collapsed\"><div class = \"title\" onclick=\"toggleTfxObject(this)\"><span class=\"expansion-marker\"></span><span class=\"class-name\">Channel</span> of type <span class=\"class-name\">'ModelBlessing'</span> (0 artifacts)<span class=\"deemphasize\"> at 0x7f7e57350a30</span></div><table class=\"attr-table\"><tr><td class=\"attr-name\">.type_name</td><td class = \"attrvalue\">ModelBlessing</td></tr><tr><td class=\"attr-name\">._artifacts</td><td class = \"attrvalue\">[]</td></tr></table></div></td></tr></table></td></tr></table></div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resolver = Resolver(\n",
    "    strategy_class=LatestBlessedModelStrategy,\n",
    "    model=Channel(type=Model),\n",
    "    model_blessing=Channel(type=ModelBlessing)\n",
    ").with_id(\"latest_blessed_model_resolver\")\n",
    "context.run(model_resolver)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[tfma.ModelSpec(label_key=\"consumer_disputed\")],\n",
    "    slicing_specs=[tfma.SlicingSpec(), tfma.SlicingSpec(feature_keys=[\"product\"])],\n",
    "    metrics_specs=[\n",
    "        tfma.MetricsSpec(\n",
    "            metrics=[\n",
    "                tfma.MetricConfig(class_name=\"BinaryAccuracy\"),\n",
    "                tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "                tfma.MetricConfig(class_name=\"AUC\")],\n",
    "            # baseline 모델과 비교해 우위에 있더라도 아래 임계치를 넘어야 bless를 받는다.\n",
    "            thresholds={\n",
    "                \"AUC\": tfma.MetricThreshold(\n",
    "                    value_threshold=tfma.GenericValueThreshold(\n",
    "                        lower_bound={\"value\": 0.65}),\n",
    "                    # 두 모델 간 지표 ∆가 0.01은 넘어야 하고, 새 모델 지표값은 클수록 좋다는 의미.\n",
    "                    change_threshold=tfma.GenericChangeThreshold(\n",
    "                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                        absolute={\"value\": 0.01}))})])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# baseline 모델을 기준으로 incoming 모델이 더 나은지 판단한다.\n",
    "# CPU-only 머신은 평가에 시간이 걸려 `examples`를 100이 되게 생성했다.\n",
    "evaluator = Evaluator(\n",
    "    examples=examples,\n",
    "    model=trained_model,\n",
    "    baseline_model=model_resolver.outputs[\"model\"],\n",
    "    eval_config=eval_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f7e44fd4bb0> and <keras.engine.input_layer.InputLayer object at 0x7f7e577a21c0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f7e44fd4bb0> and <keras.engine.input_layer.InputLayer object at 0x7f7e577a21c0>).\n"
     ]
    }
   ],
   "source": [
    "context.run(evaluator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts/examples\n"
     ]
    }
   ],
   "source": [
    "root_dir = pathlib.Path(\"artifacts\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_result = evaluator.outputs[\"evaluation\"].get()[0].uri\n",
    "tfma_result = tfma.load_eval_result(eval_result)\n",
    "\n",
    "blessing = evaluator.outputs[\"blessing\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_path = evaluator.outputs['evaluation'].get()[0].uri\n",
    "\n",
    "# Load the evaluation results.\n",
    "eval_result = tfma.load_eval_result(output_path)\n",
    "\n",
    "# Load the validation results\n",
    "validation_result = tfma.load_validation_result(output_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pusher"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_serving_model_dir = \"serving_model_dir\"\n",
    "\n",
    "pusher = Pusher(model=trained_model,\n",
    "                model_blessing=blessing,\n",
    "                push_destination=pusher_pb2.PushDestination(filesystem=pusher_pb2.PushDestination.Filesystem(base_directory=_serving_model_dir)))\n",
    "context.run(pusher)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
